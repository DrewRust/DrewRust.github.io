<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Exoplanets and Data Modeling</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
        <style>
        
        span.lowercase {
            text-transform: lowercase;
        }
        img.contain {
            object-fit: contain;
        }
        
        </style>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
                        <a href="index.html" class="logo">Projects</a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li><a href="index.html">Projects Main</a></li>
							<li><a href="about.html">About Me</a></li>
							<li class="active"><a href="planet-data.html">Exoplanets Project</a></li>
						</ul>
						<ul class="icons">
                            <li><a href="https://www.linkedin.com/in/andrew-rust-1761599a/" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
                        <!-- <li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li> -->
                        <!-- <li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li> -->
                        <!-- <li><a href="#" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li> -->
							<li><a href="https://github.com/DrewRust" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">
								<header class="major">
                                   
									<h1>NASA Exoplanets</h1>
                                    <header class="major">
                                        <span class="date">Data Modeling</span>
                                    </header>
                                   <a href="https://commons.wikimedia.org/wiki/File:NASA-KeplerSpaceTelescope-ArtistConcept-20141027.jpg#/media/File:NASA-KeplerSpaceTelescope-ArtistConcept-20141027.jpg" class="image main"><img src ="images2/NASAKeplerSpaceTelescope.jpg" alt="FindImage."/> </a>
								</header>

								<!-- Text stuff -->
                                
                                <h2>Exoplanets are planets outside our solar system.  Is the exoplanet Confirmed?  </h2>
                                <h3>Above is an artist's rendering of NASA's Kepler Space Telescope in search of them.<a href="https://solarsystem.nasa.gov/solar-system/beyond/overview/">NASA documents 4,164 and counting "Confirmed" exoplanets</a> discovered so far and thousands of other "Candidate" planets.  Below is the process I used to create data models using telescope observations to predict a planet's status.</h3>
                                <hr/>
                                
                                
                                <p>
                                As of writing this there are 4,164 "confirmed" exoplanets.  The other "candidate" planets require more study to be confirmed.  The discovery method most often successful is the transit method as the exoplanet passes in between it's star and the telescope.  The dimming of the light from that star can then be measured and the orbit studied.</p>
                                
                                <p>
                                I chose the <a href="https://exoplanetarchive.ipac.caltech.edu/cgi-bin/TblView/nph-tblView?app=ExoTbls&config=PS"> Planetary Systems Alpha release dataset</a> which is essentially all the planetary data combined.  The data consists of 26,336 rows and 118 columns.  Out of 118 columns some just had too many missing values, others were not helpful to predict if it's a confirmed planet, or the column variable was hard to understand.  After all, understanding the data can be important to not leak training data to testing data.</p>
                                <hr/>
                                
                                
                                <h2>Links to follow along:</h2>
                                        <ol>
                                            
                                    <li><a href="https://colab.research.google.com/drive/1_2SC3zSGWn0LPwKYCXeLUTqFncqAQPo8?usp=sharing">My Visual Data Anaylsis Code Here.</a></li>
                                            
                                    <li><a href="https://colab.research.google.com/drive/1NZ1I2sXOvmqm2zpETU3psVQWup-ah76S?usp=sharing">My Predictive Model Code Here.</a></li>
                                    
                                    <li><a href="https://github.com/DrewRust/DS-Unit-2-Build_Week">Same Code on Github Here.</a></li>
                                            
                                    <li><a href="https://exoplanetarchive.ipac.caltech.edu/docs/ICEexohelp.html">Planetary Systems Data Used Here.</a></li>
                                    
                                    <li><a href="https://exoplanetarchive.ipac.caltech.edu/docs/exoplanet_criteria.html">Criteria for Exoplanet Status.</a></li>

                                    
                                    <li><a href="https://exoplanets.nasa.gov/exoplanet-catalog/">Exoplanet Exploration and Interactive NASA Site Here.</a></li>
                                    
                                    
<!--                                 <li><a href="https://www.kaggle.com/ezietsman/kepler-dataset-exploratory-analysis">Kepler Data explored on Kaggle by Ewald Zietsman.</a></li>-->
                                        </ol>
                                <hr/>
                                
                                
                                <h3>The first thing was to explore the <a href="https://exoplanetarchive.ipac.caltech.edu/docs/API_PS_columns.html">data columns.</a>  Initially I had 118 different data columns so I narrowed it down to 25.  Out of these 22 were numeric data types and 3 were categorical types.  I'm first going to describe the numeric columns of planetary data.</h3>
                                <hr/>
                                
                                
                                <h2>Numeric Columns</h2>
                                <hr/>
                                
                                
                                
                                <h3>Heatmap</h3>
                                <img src="images2/heatmap.png" class = "image main" alt="imagedescription">
                                    
                                    <h3>The heatmap shows any correlations between the <a href="https://exoplanetarchive.ipac.caltech.edu/docs/API_PS_columns.html">columns.</a></h3>
                            
                                <ul>
                                    <li>Each column shows up once on the left margin and again at the bottom.</li>
                                    <li>The diagonal line is created because of course the column is highly correlated with itself.</li>
                                    <li>"dec" and "ra" are the location cooridinates of the planets.</li>
                                    <li>The columns beginning with "sy" refer to the planetary systems.  Notice how they're grouped together and create a pattern.</li>
                                    <li>The columns begining with "pl" refer to the exoplanets.  "pl_radj" and "pl_rade" refer to the radii or radiuses of the planets measured in units of Jupiters and Earths.  There are definitely some correlations among these.</li>
                                    <li>The columns begining with "st" refer to the star the exoplanet orbits.  Notice how these create a pattern.</li>
                                </ul>
                                <hr/>
                                
                                
                                
                                <h3><span class="lowercase">"pl_eqt"</span> is the planet's temperature.</h3>
                                <img src="images2/pl_eqt.png" class = "image main" alt="imagedescription">
                                    
                                    <p>This boxplot shows Confirmed planets in magenta have on average a warmer temperature.</p>
                                <hr/>
                                
                                
                                
                                
                                <h3><span class="lowercase">"pl_orbper"</span> is orbit time in days and <span class="lowercase">"pl_ratdor"</span> is a ratio of distance from the planet to it's star.</h3>
                                <img src="images2/pl_ratdor_orbper.png" class="image main" alt="imagedescription">
                                    <p>This scatterplot shows Confirmed planets in teal are more closely grouped with shorter orbit times.  Overall, the farther away a planet is the longer time it takes to orbit the star.</p>
                                <hr/>
                                
                                
                                
                                
                                <h3><span class="lowercase">"pl_trandep"</span> is flux caused by transit of the planet and <span class="lowercase">"pl_radj"</span> is the planet radius measured in Jupiter units.</h3>
                                <img src="images2/pl_trandep_radj.png" class="image main" alt="imagedescription">
                                    <p>This scatterplot shows Confirmed planets in green cause more flux or change in brightness of the star by their transit.  Overall, larger planets cause more flux.</p>
                                    <hr/>
                                    
                                    
                                    
                                    <h3><span class="lowercase">"pl_trandurd"</span> is the transit duration in hours.  <span class="lowercase">"pl_rade"</span> is the planet radius in earth units.  <span class="lowercase">"st_mass"</span> is the stellar mass (C<span class="lowercase">lick to enlarge).</span></h3>
                                        <a href="Transit_duration_hrs.html" class="image main"><img src="images2/pl_trandurd.png" alt="Graph of Transit Duration" /></a>
                                        <p>The transit duration in hours will be a very important predictor <a href="#pl_trandurd">(see feature importances)</a> because it's longer for planets that have NOT been confirmed. The stellar masses on the y axis shows little difference.  Planet radii on the color bar shows some differences especially if you zoom in.  To zoom in click on the graph and there's a tool bar at the top right to zoom and a pan tool to see different areas. </p>
                                        <hr/>
                                        
                                    
                                    
                                    <h3><span class="lowercase">"pl_imppar"</span> is the distance of planet to star.  <span class="lowercase">"pl_ratror"</span> is the ratio of planet to star radius.</h3>
                                    <img src="images2/pl_imppar_ratror.png" class="image main" alt="imagedescription">
                                        <p>This linear regression scatter plot shows Confirmed and Candidate planets are grouped differently.  The linear trendlines are different too.</p>
                                    <hr/>
                                    
                                    
                                    
                                    
                                    <h3><span class="lowercase">"pl_ratdor"</span> is a ratio of distance from the planet to it's star.  <span class="lowercase">"pl_eqt"</span> is the planet's temperature.</h3>
                                    <iframe id="igraph" scrolling="no" style="border:none;" seamless="seamless" src="https://plotly.com/~drewrust1/3.embed" height="525" width="100%"></iframe>
                                        <p>As the distance increases (X axis) the planet temperature decreases (y axis).  So distance and temperature are correlated by if the planet is cooler it must be farther away from it's star. Overall, there's less distance from planet to it's star for confirmed planets.</p>
                                        <hr/>
                                        
                                
                                
                                <h3><span class="lowercase">"ra"</span> is the planet's longitude east and west coordinates.<span class="lowercase">"dec"</span> is the planet's latitude north and south coordinates.<span class="lowercase">"st_mass"</span> is the stellar mass (C<span class="lowercase">lick to enlarge).</span></h3>
                                <a href="rightAscDec.html" class="image main"><img src="images2/rightAscDec.png" alt="Graph of Transit Duration" /></a>
                                
                                <p>Right ascension and declination are the equivalent of longitude and latitude for an object's celestial coordinates.  Here it's easy to see all the confirmed and candidate planets.  Kepler's original mission is focused on the top right darker square shape.  Kepler in it's original operational condition no longer works the same but is now functioning as K2.  K2's discoveries go across in a swooped line.</p>
                                
                                <ul>
                                    <li><a href="https://exoplanets.nasa.gov/resources/1019/kepler-field-of-view/">Original Kepler Mission Telescope Field of View Link Here.</a></li>
                                    <li><a href="https://keplerscience.arc.nasa.gov/images/k2_graphic_sm.jpeg">K2 Quadrants Pictured in Link Here.</a></li>
                                </ul>
                                
                                <hr/>
                                <h2>Categorical Columns</h2>
                                <hr/>
                                
                                
                                <h3><span class="lowercase">"discoverymethod"</span> is obviously how the planet was discovered.</h3>
                                <img src="images2/discoverymethod.png" class="image main" alt="imagedescription">
                                <p>Transit is clearly the most common and is how Kepler made it's discoveries.  Radial Velocity is when the star wobbles slightly because of the gravitational pull of its orbiting exoplanet.  Radial Velocity was used to discover all confirmed planets which is a good predictor.</p>
                                
                                
                                <h3><span class="lowercase">"disc_locale"</span> is of course where the planet was discovered.</h3>
                                <img src="images2/disc_locale.png" class="image main" alt="imagedescription">
                                    <p>Planets discovered on the ground are more likely to be confirmed planets.  The clear majority of the rest of planets were discovered in space by Kepler like telescopes that can reach farther and see better images.</p>
                                
                                
                                <h3><span class="lowercase">"st_metratio"</span> is the star's metal ratio.</h3>
                                <img src="images2/st_metratio.png" class="image main" alt="imagedescription">
                                    <p>Ratio for the Metallicity Value [Fe/H] denotes an iron abundance, [M/H] refers to a general metal content.  So there are more candidate unconfirmed planets in the iron column and more confirmed planets in the general metal column.  These two features will likely be important predictors.</p>
                                <hr/>
                                
                                
                                <h2>Predicative Model Making - Is the exoplanet confirmed or not?</h2>
                                <hr/>
                                
                                <h3>Baseline &amp; Logistic Regression (LR) Model</h3>
                                <h4>Using the numeric columns: <span class="lowercase">"pl_eqt", "pl_orbper", "pl_ratdor", "pl_trandep", "pl_radj", "pl_ratror", "pl_imppar", "st_mass", "pl_trandurd", "pl_rade", "ra", "dec"</span> and the categorical columns <span class="lowercase">"st_metratio", "discoverymethod", "disc_locale"</span></h4>
        
        
                                        <ul>
                                            <li>The best guess would be True because True's have a 53.7% majority.</li>
                                            <li>The first predictive model using Logistic Regression improved the best guess prediction to a 90.2% certainty.</li>
                                        </ul>
                               
        
                                <img src="images2/baseline.png" class="image main" alt="imagedescription">
        
        
        
                                    
                                 <h3>Confirm Logistic Regression Score</h3>
                                 
                                 <ul>
                                     <li>There were a total of 4,938 predictions made.  4,453 were right and 485 were wrong giving the model score a 90.2%</li>
                                     <li>The model's accuracy score was verified by dividing the number of correct predictions by the total number of predictions and everything matched.</li>
                                     <li>The first 5 LR Model predictions which all happened to be correct can be seen below along with the planet names.
                                    <li>So only a little less than 10% of the predictions were wrong.</li>
                                     </ul>
                                 
                                 
                                <img src="images2/LRcorrect.png" class="image main" alt="imagedescription">
                            
                            
                                    <h3 id = "pl_trandurd">LR feature importances (permuted)</h3>
                                    
                                        <ul>
                                            <li>Permuted means the feature's importance was double checked by shuffling it, then finding it's impact on model accuracy.
                                            <li>Obviously the features with the most green were the most important to the model's success.
                                            <li>There are a lot of features here that aren't helping the model so let's run it again using the best features.</li>
                                            </ul>
                                    
                                    <img src="images2/logisticfeatures.png" class="image main" alt="imagedescription">
                                    
                                   
                                    
                                    <h3>LR with top features</h3>
                                    
                                    <ul>
                                        <li>With the 11 most important features above the model test accuracy was still great at 90% (rounded up).</li>
                                        <li>Out of all the 30 features we really only needed 11 to create a predictive model.</li>
                                        <li>In a Kaggle Competition we would keep all features with an importance above 0.0% to get every small bit of improvement in the model score.  With this model the feature importance cut off was 0.005.  The prediction score only lost 0.2% accuracy, down from 90.2% to 90%. </li>
                                        </ul>
                                    
                                    
                                    <img src="images2/LRrerun.png" class="image main" alt="imagedescription">
                                       
                                    
                                <hr/>
                                

                            <h3>Decision Tree Model</h3>


                            <h4>U<span class="lowercase">sing</span> only <span class="lowercase">these columns:</span><span class="lowercase">"pl_rade", "pl_orbper", "st_mass", "discoverymethod"</span></h4>
                            
                            <ul>
                                <li>The <strong>Decision Tree Model</strong> and the following models use <strong>only 4 columns.</strong></li>
                                <li>With Decision Trees to avoid overfitting the training data <strong>max_depth</strong> is a parameter that should be defined.  For the next visual it was set to 4.</li>
                                <li>This helps the model keep generalized for the unpredictable test set and new data.</li>
                                <li>Here is a visual understanding how the DT set decision points to make predictions.  The True's can be visualized in the color yellow and the False's in the color blue-green.</li>
                                </ul>
                            

                            <img src="images2/dtree.png" class="image main" alt="imagedescription">
                               
                             <ul>
                                <li>Another Decision Tree Visual using the <strong><a href="https://github.com/parrt/dtreeviz">Dtreeviz Library (link)</a></strong> with the <strong>max_depth</strong> set to 3.  It uses a pie chart visual to make the model easier to interpret.</li>
                                <li>Here the root node is "pl_rade" meaning the decision process starts here.  If it is <i>less than</i> it goes to the next decision which is "pl_orbper" (the majority here were <strong>candidate 0</strong>).  If it is <i>greater than or equal to</i> it goes to the next decision which is "pl_rade" (the majority of these were <strong>confirmed 1</strong>).  This process continues until the decision classifies that planet as confirmed or not confirmed.</li>
                                </ul>

                            <img src="images2/dectreeviz.jpg" class="image main" alt="imagedescription">
    
                                <ul>
                                    <li>The <strong>Decision Tree Model</strong> score was first ran with a <strong>max_depth</strong> kept at it's default of None and had an accuracy of 79.1% on the test set.</li>
                                    <li>It was then ran again with a <strong>max_depth</strong> of 3 and it didn't overfit the training data but it did lose a very small amount of test accuracy.  Down from 79.1% to 78.6%.</li>
                                    <li><strong>79.1%</strong> is used below in the final summary &amp; comparison.</li>
                                </ul>
    
                                <hr/>
    
                            <h3>Random Forest Model</h3>
                            
                            <h4>Continuing with the same columns: <span class="lowercase">"pl_rade", "pl_orbper", "st_mass", "discoverymethod"</span></h4>

                            <ul>
                            <li>The Random Forest Model is just a bunch of Decision Trees ran using the feature columns.  Then the most popular prediction (confirmed or not) is used in the final.  Kind of like getting multiple opinions or estimates on a car before fixing it instead of just going with the first estimate.</li>
                            <li><strong>The Random Forest Model feature importances.</strong></li>
                           </ul>

                                <img src="images2/Rf_imp_feat.png" class="image main" alt="imagedescription">
                                    <p><strong>Random Forest Model with adjusted parameters improves the test score to 81.2%.</strong></p>

                                <ul>
                                <li>The default of 100 <strong>n_estimators</strong> was changed to 200.</li>
                                <li>The default of None <strong>max_depth</strong> was changed to 15.</li>
                                <li>The default of 2 <strong>min_samples_split</strong> was changed to 5.</li>
                                <li>The default of 1 <strong>min_samles_leaf</strong> was the only parameter not changed and left at 1.</li>
                                <li>New test score of 81.2%.</li>
                                </ul>

                                <img src="images2/Rf_adj.png" class="image main" alt="imagedescription">

                                <hr/>
                                
                                
                                <h3>Cross Validation Model and Summary</h3>
                                
                                <h4>Same columns: <span class="lowercase">"pl_rade", "pl_orbper", "st_mass", "discoverymethod"</span></h4>
                                
        
                                <ul>
                                    <li><strong>Cross Validation</strong> is the final model and does not use a validation set. It runs with the train and test sets only.  This way the training data sample is larger and can create a more accurate model.</li>
                                    <li>The CV Model uses the RandomizedSearchCV method meaning the parameters were chosen randomly from a created parameter list.</strong></li>
                                    <li><strong>n_iter</strong> was set at 20 which is how many random parameters were sampled for each run.</li>
                                    <li><strong>cv</strong> was set at 5 meaning 5 models were ran and the model with the best score &amp; parameters was kept to run on the test set.</li>
                                    <li>Cross Validation had the best test score of <strong>82.4%</strong> as seen below.</li>
                                    <li>Out of all the other models it took the longest to run about 5 minutes.</li>
                                     <li>Beginning with The Decision Tree, next The Random Forest, RF Adjusted, and finally The CV each model saw an improvement in test accuracy.</li>
                                </ul>
                                
                                <img src="images2/summary.png" class="image main" alt="imagedescription">
                                
                                <ul>
                                <li>The <strong>Confusion Matrix of the Cross Validation Model</strong> just shows the correct True &amp; False predictions match and the totals are correct.</li>
                                <li> The CV Model's False predictions were correct 2,849 times.  It's True predictions were correct 2,575 times.  It was wrong a total of 1,160 times (found by adding 949 plus 211).</li>
                                <li>We can verify our accuracy score by dividing the correct predictions by the total predictions.  The result is <strong>82.4%</strong> which matches above.</li>
                                </ul>
                                
                                <img src="images2/confusion_m.png" class="image main" alt="imagedescription">
                                
                                 <hr/>
                                
                                <h2>Conclusion</h2>
                                <p>This was a big dataset so it was really helpful to reduce the number of columns to better understand them.  Beginning with the Logistic Regression Model more columns were used to initially train the model.  Starting with 12 numeric and 3 categorical columns.  The 3 categorical columns would later become 18 features after being seperately encoded.  For instance, the column "st_metratio" became 5 seperate features.  The column "discoverymethod" became 9 and "disc_locale" would become 4 to create 18. Those added to the 12 numeric features created a total of 30 features. The model was trained and then again with only 11 of the most important features.</p>
                                
                                <p>Using all the same features for the Decision Tree Model it was able to fit itself to a 99.3% accuracy.  So using 3 numeric columns and 1 categorical column it gave the Decision Tree and other Models more of a challenge.  After running a Random Forest and changing the parameters the score improved.  The best predictive model score with those 4 columns came from a Cross Validation Model.  For this project I learned a lot about predictive data modeling through the interesting topic of exoplanets.  Thank you for following along.</p>
                                
                                <hr/>
                                </div>
                                </div>
            

                 
				<!-- Copyright -->
					<div id="copyright">
						<ul><li>&copy; Andrew Rust</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li></ul>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
